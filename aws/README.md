Brewery Microservices on AWS
=====================================================
This directory contains a Cloud Development Kit (CDK) project, written in TypeScript, that demonstrates how to deploy an 
example cluster of brewery microservices onto AWS Elastic Container Service.

It's not meant to be a production ready deployment. It's merely an example of how to use the cdk to create 
the resources needed to run the existing brewery microservice architecture.

It mirrors the architecture of the [docker-compose](../docker-compose.yml) network from the main project, and will deploy one
of each type of the following servers:
- one zipkin server
- one artemis server
- one eureka server
- one config server
- one inventory-service server
- one inventory-failover-service server
- one beer-service server
- one order-management server

Each of the above servers will be running on ec2 t3.medium instances.

Additionally, the following additional AWS resources will be created:
- A VPC with one private and one public subnet spread across two AZs
- A NAT gateway to give the container instances access to docker hub from the private subnet
- one AWS RDS instance - to run the mysql database
- one bastion server, running in the public subnet, used to configure the RDS MySQL instance
- AWS CloudMap - for DNS service discovery
- one Application Load Balancer - to route traffic from the internet, to the respective web consoles of the 
zipkin server, eureka server and the config server


All usernames and passwords, for the web-consoles etc..., have been ported over from the main project and remain unchanged.


## Running
It's assumed you are familiar with AWS, the aws cli, and aws cdk, etc... and that you have installed the aws cdk.


The microservices are created using two different stacks:
- a `BreweryInfrastructureStack` which creates the VPC, RDS MySQL instance, one bastion server, application load balancer, and a CloudMap namespace.
- a `BreweryServicesStack` which creates the zipkin, artemis, eureka, config server, inventory-service, failover-service, order-service and beer-service containers

Note that you will need to have your own key-pair (.pem) file handy in order to access the bastion server.


### Step 1
create the brewery infrastructure stack. We will pass the name of your keypair file as a context parameter
> cdk deploy --context keyPairName=<YOUR-KEYPAIR-FILE-NAME> BreweryInfrastructureStack

for example: `cdk deploy --context keyPairName=cliff-aws-keypair BreweryInfrastructureStack`

Wait for the resources to be created. It can take some time to create the RDS instance (on average 5 minutes). 

Once created the public hostname of the bastion server, public hostname of the load balancer, and private hostname of the RDS instance will be output to the terminal.


### Step 2
In this step we create the required MySQL databases using the bastion server to connect to the RDS instance. 
The [mysql-init-all.sql](./mysql-init-all.sql) DDL should be used to create the required databases and users.
The root username and password for the RDS instance is: `root` `password`

copy the `mysql-init-all.sql` file to the bastion instance
> scp -i <PATH-TO-YOUR-KEYPAIR-FILE>.pem mysql-init-all.sql ec2-user@<BASTION-SERVER-HOSTNAME>:./


ssh to bastion server
> ssh -i <PATH_TO_.pem> ec2-user@BASTION_SERVER_DNS_NAME_OR_IP


update the bastion server and install mariadb (used for connecting to mysql)
> sudo yum update
> sudo yun install mariadb
> mysql --version


connect to the remote mysql server
> mysql -h DB_PRIVATE_HOSTNAME_OR_IP -P 3306 -u root -p


enter password when prompted


now run the ddl file
> \. mysql-init-all.sql


check if databases created, show see three new databases: `beerinventoryservice`, `beerorderservice`, `beerservice`
> SHOW DATABASES;


check if users created
> SELECT User, Host FROM mysql.user;


### Step 3
in this step we deploy the brewery microservices into ECS.

- deploy the `BreweryServiceStack`
> cdk deploy BreweryServicesStack

Once this stack is created, you should be able to connect to the zipkin server web console on port 9411 using the hostname of the application loadbalancer...
> http://APPLICATION-LOAD-BALANCER-HOSTNAME:9411/zipkin

once the page loads, you can click the blue query button and if all went well, you shou see all the sagas that have been generated by the order-service.



## Destroying the stacks
to destroy both stacks:
> cdk destroy --all

this will begin removing all resources. **NOTE: the cdk currently hangs when it tries to delete the Auto Scaling Groups. You 
will need to manually delete the Auto-Scaling groups yourself in the AWS web console**

once you delete the ASGs, the cdk will notice they are deleted and will proceed to delete the remaining resources. 

Verify that all resources were in deleted via the AWS web console.